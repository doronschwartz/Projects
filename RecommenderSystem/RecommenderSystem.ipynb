{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Doron Schwartz, 05/22/23,Final Project"
      ],
      "metadata": {
        "id": "B29D3igQp9J2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from surprise import Reader, Dataset, SVD\n",
        "from surprise.model_selection import cross_validate, train_test_split\n",
        "from surprise.accuracy import rmse\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnI1MnXis3NJ",
        "outputId": "5a3534ad-53b6-466e-b4d0-7d3625fb8ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.10/dist-packages (1.1.3)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.10.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load in the imbd data with the rating, and we also load in the genre data for the Simple and Hybrid Models later. We rename the columns for reference, with the last bunch of columns being the vector of genres"
      ],
      "metadata": {
        "id": "0MJ-cCDaC0lO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"http://files.grouplens.org/datasets/movielens/ml-100k/u1.base\", sep='\\t', header=None, names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"])\n",
        "\n",
        "item_data = pd.read_csv(\"http://files.grouplens.org/datasets/movielens/ml-100k/u.item\", sep='|', header=None, encoding=\"ISO-8859-1\")\n",
        "\n",
        "item_data.columns = [\"movieId\", \"title\", \"release_date\", \"video_release_date\", \"IMDb_URL\", \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"]"
      ],
      "metadata": {
        "id": "Om7EGm0cECJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do a train-test split."
      ],
      "metadata": {
        "id": "HYzB1s_nIGmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = sklearn.model_selection.train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "mg-HgUz0IJGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline Model"
      ],
      "metadata": {
        "id": "c53G92iUUjJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the baseline model, we will just take the mean rating across all the ratings in the training data is calculated as the baseline rating. The baseline model predicts this mean rating for all cases in the test data."
      ],
      "metadata": {
        "id": "KkqvHRXJLJ_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can take the mean of the training data"
      ],
      "metadata": {
        "id": "hVGU9G2Mb6VB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_rating = train_data['rating'].mean()\n"
      ],
      "metadata": {
        "id": "jZRs8UmhcFPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a quick function that retrieves the mean rating, and we run it through the test data"
      ],
      "metadata": {
        "id": "57si7GSLcHlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model():\n",
        "    return mean_rating\n",
        "\n",
        "baseline_predictions = [baseline_model() for _ in range(len(test_data))]"
      ],
      "metadata": {
        "id": "7cZmAZDCc0ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quick functions to get the RMSE"
      ],
      "metadata": {
        "id": "Kd_ABAWKc9-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(predictions, targets):\n",
        "    return np.sqrt(((predictions - targets) ** 2).mean())\n"
      ],
      "metadata": {
        "id": "ALjTQxyfdhlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the Baseline RMSE and print it out"
      ],
      "metadata": {
        "id": "SUe3WItrdk26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_rmse = rmse(baseline_predictions, test_data['rating'])\n",
        "print(\"Baseline RMSE:\", baseline_rmse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIXEqeX_tNKX",
        "outputId": "850f7a02-7e6b-4a14-f014-0fe7788c6d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline RMSE: 1.1244493378879115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple Model"
      ],
      "metadata": {
        "id": "QXRJp_-KLd2-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The simple model will be focused on collarbitive filtering, and will be based on a SVD model, which is a Singular Value Decompisiton(SVD), which will take the matrix and reduce it to the most important featues."
      ],
      "metadata": {
        "id": "NpHwSrD4fyR4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have the rating and genre merged here for Hybrid model purposes, but join them now at the Model stage at MovieID"
      ],
      "metadata": {
        "id": "1TxVg_oEA63A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data = pd.merge(df, item_data, on=\"movieId\", how=\"left\")"
      ],
      "metadata": {
        "id": "0SAAMKaJBDFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the Surprise Library, we load in the Scaler which has the ratings between 1 and 5, and we load in the data into a Surprise Dataset"
      ],
      "metadata": {
        "id": "erFYUogfBvf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(merged_data[['userId', 'movieId', 'rating']], reader)\n"
      ],
      "metadata": {
        "id": "CbOvYBubDATg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do a Train/Test split on the processed data"
      ],
      "metadata": {
        "id": "Cs4OtW48DAfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "q4cCNiXlDFW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make the matrix factorization/SVD Model"
      ],
      "metadata": {
        "id": "Czh05PBoDGZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_one = SVD()"
      ],
      "metadata": {
        "id": "UcTmpdK0DI3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit the model to the training data"
      ],
      "metadata": {
        "id": "M0Qyyu12DO8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_one.fit(trainset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdlBXJNKEZvR",
        "outputId": "297ab4dc-d65b-4821-f8c9-9f823e99d448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7f5b65ebaef0>"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pull predictions from the model, get the actual ratings and the predicted ratings for the model"
      ],
      "metadata": {
        "id": "-6QyuH0CInfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model_one.test(testset)\n",
        "actual_ratings = np.array([pred.r_ui for pred in predictions])\n",
        "predicted_ratings = np.array([pred.est for pred in predictions])\n"
      ],
      "metadata": {
        "id": "eTqv2jUZIqnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the RMSE from the predictions"
      ],
      "metadata": {
        "id": "NabJtXcI9KTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(actual_ratings, predicted_ratings)\n",
        "rmse_score = np.sqrt(mse)\n",
        "print(\"RMSE:\", rmse_score)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XfM3b5tLfCX",
        "outputId": "ce3a9507-0248-421e-9e2c-39a437cc914b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.9404862627972276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hybrid Model"
      ],
      "metadata": {
        "id": "ttpnNgwtcBIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the Hybrid Model, we will combine the Collorabtaive filtering of the SVD, and take the Genres and embedd them to get a content filtering aspect. WE can then throw it into the DNN and see how well it is able to predict at that point."
      ],
      "metadata": {
        "id": "3MNlbieR9-cN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From before, we had the merged data, so we can just throw it into the Scaler and load into a Surprise Dataset"
      ],
      "metadata": {
        "id": "Kt1I6eeeAWOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the rating scale using Surprise library\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(merged_data[['userId', 'movieId', 'rating']], reader)\n"
      ],
      "metadata": {
        "id": "rduBW8cuCMn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pull out the data we need from the sheet."
      ],
      "metadata": {
        "id": "LXDXnKWcCZXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_data = pd.DataFrame(data.raw_ratings, columns=[\"userId\", \"movieId\", \"rating\", \"timestamp\"])"
      ],
      "metadata": {
        "id": "pqO39lcNDMIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the Data into train/test"
      ],
      "metadata": {
        "id": "wkZlPRO9DMwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = sklearn.model_selection.train_test_split(df_data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "oPR9qpN7GkRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make the Surprise dataset from the training"
      ],
      "metadata": {
        "id": "HA3Q8NcAGlLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = Dataset.load_from_df(train_data[['userId', 'movieId', 'rating']], reader)"
      ],
      "metadata": {
        "id": "-ZN8MlkRHImK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the SVD model and get it fit for the trainset"
      ],
      "metadata": {
        "id": "mmNRPrjFHK1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svd_model = SVD()\n",
        "svd_model.fit(trainset.build_full_trainset())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORXGoy1THXgb",
        "outputId": "86f10c85-87f9-44b0-cbf9-7b24752a6a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7f5b63cab580>"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieve the Genre data"
      ],
      "metadata": {
        "id": "bzbTl14UHX_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genre_features = merged_data[['Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']].values"
      ],
      "metadata": {
        "id": "h5rupO1jHcpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the Standard Scaler, which scales the features."
      ],
      "metadata": {
        "id": "duD2G8b-HiBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "genre_features_scaled = scaler.fit_transform(genre_features)"
      ],
      "metadata": {
        "id": "CU5GEkpnHrZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No we want to build an autoencoder for the genre data, fit in the genre data and the encoding demnsions"
      ],
      "metadata": {
        "id": "YavAlHoAHsVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim_genre = genre_features_scaled.shape[1]\n",
        "encoding_dim_genre = 32"
      ],
      "metadata": {
        "id": "nRZO5wXLIEu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make the encoding layer with the correct dimensions from above"
      ],
      "metadata": {
        "id": "tyE4DU-NIDn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer_genre = Input(shape=(input_dim_genre,))\n",
        "encoder_genre = Dense(encoding_dim_genre, activation='relu')(input_layer_genre)\n",
        "decoder_genre = Dense(input_dim_genre, activation='sigmoid')(encoder_genre)\n"
      ],
      "metadata": {
        "id": "iMXmS2KsILaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the Autoencoder itself"
      ],
      "metadata": {
        "id": "-sVOSDweIM4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_genre = Model(inputs=input_layer_genre, outputs=decoder_genre)\n",
        "autoencoder_genre.compile(optimizer='adam', loss='mean_squared_error')\n",
        "autoencoder_genre.fit(genre_features_scaled, genre_features_scaled, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYIrJloMIPzQ",
        "outputId": "28fc0013-f8b9-4842-ba0f-5740f960f8f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2500/2500 [==============================] - 10s 4ms/step - loss: 0.6238\n",
            "Epoch 2/10\n",
            "2500/2500 [==============================] - 9s 4ms/step - loss: 0.5621\n",
            "Epoch 3/10\n",
            "2500/2500 [==============================] - 6s 2ms/step - loss: 0.5615\n",
            "Epoch 4/10\n",
            "2500/2500 [==============================] - 4s 2ms/step - loss: 0.5614\n",
            "Epoch 5/10\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.5613\n",
            "Epoch 6/10\n",
            "2500/2500 [==============================] - 4s 2ms/step - loss: 0.5613\n",
            "Epoch 7/10\n",
            "2500/2500 [==============================] - 4s 2ms/step - loss: 0.5613\n",
            "Epoch 8/10\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.5613\n",
            "Epoch 9/10\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.5613\n",
            "Epoch 10/10\n",
            "2500/2500 [==============================] - 5s 2ms/step - loss: 0.5613\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5b63b1eec0>"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieve the genre embeddings and the SVd embeddings"
      ],
      "metadata": {
        "id": "oneFvzahIRqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genre_embeddings = autoencoder_genre.predict(genre_features_scaled)\n",
        "svd_embeddings = svd_model.qi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT04-J05IVw-",
        "outputId": "96e82c41-5f4d-4142-92d0-56c521e609e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500/2500 [==============================] - 4s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the test ratings."
      ],
      "metadata": {
        "id": "7sF8y222L6ge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_ratings = test_data['rating'].values"
      ],
      "metadata": {
        "id": "lNZ-IHO3L-QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Truncate the embeddings in order to have a working combination"
      ],
      "metadata": {
        "id": "nI3D3bRxCakb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genre_embeddings_truncated = genre_embeddings[:svd_embeddings.shape[0]]"
      ],
      "metadata": {
        "id": "Y-OXEMG2JGNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine the SVD and Genre embeddings"
      ],
      "metadata": {
        "id": "jMqh3_kdMYIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_embeddings = np.concatenate((genre_embeddings_truncated, svd_embeddings), axis=1)"
      ],
      "metadata": {
        "id": "VJLZ8s7vMWko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can build the DNN Model, with three layers of 64/32 and the linear at the end."
      ],
      "metadata": {
        "id": "uY1mvVZ5MeOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_two = Sequential()\n",
        "model_two.add(Dense(64, activation='relu', input_shape=(combined_embeddings.shape[1],)))\n",
        "model_two.add(Dense(32, activation='relu'))\n",
        "model_two.add(Dense(1, activation='linear'))"
      ],
      "metadata": {
        "id": "we9OBmZ9MkGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile and fit the DNN model"
      ],
      "metadata": {
        "id": "6SLizLU8Ml24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_two.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "model_two.fit(combined_embeddings, test_ratings[:combined_embeddings.shape[0]], epochs=10, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbP3d9NZMp1c",
        "outputId": "10a9ae41-f4cb-4fc2-de3e-de1aa13db60b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "51/51 [==============================] - 1s 2ms/step - loss: 7.0637\n",
            "Epoch 2/10\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 1.6394\n",
            "Epoch 3/10\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 1.3484\n",
            "Epoch 4/10\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 1.2238\n",
            "Epoch 5/10\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 1.1518\n",
            "Epoch 6/10\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 1.0772\n",
            "Epoch 7/10\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 1.0290\n",
            "Epoch 8/10\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 0.9826\n",
            "Epoch 9/10\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 0.9374\n",
            "Epoch 10/10\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 0.9020\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5b486bee90>"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the predicited rating and pull"
      ],
      "metadata": {
        "id": "-dF87WcbJWlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "predicted_ratings = model_two.predict(combined_embeddings)\n",
        "rmse_score = np.sqrt(mean_squared_error(test_ratings[:combined_embeddings.shape[0]], predicted_ratings))\n",
        "print(\"RMSE:\", rmse_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnZQP-MGMu2p",
        "outputId": "405c8b65-538c-495d-9218-57b8745afb06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51/51 [==============================] - 0s 2ms/step\n",
            "RMSE: 0.9152785904274006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "AQWgy3sfODoQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will do seperate testing on the Simple and Hybrid models, we will load in the test file and process it like we did the training data"
      ],
      "metadata": {
        "id": "L4n8ISG4OT_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_data = pd.read_csv(\"http://files.grouplens.org/datasets/movielens/ml-100k/u1.test\", sep='\\t', header=None, names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"])\n",
        "test_ratings = df_test_data['rating'].values"
      ],
      "metadata": {
        "id": "TnbdorgNOwOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple"
      ],
      "metadata": {
        "id": "JrbUupqyOhua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Push the test data through the same way we did in the train/test split, and pull the RMSE"
      ],
      "metadata": {
        "id": "JNtUTv7KOlvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_ratings = df_test_data['rating'].values\n",
        "\n",
        "# Prediction\n",
        "predicted_ratings_simple = model_one.test(df_test_data[['userId', 'movieId', 'rating']].values)\n",
        "\n",
        "#Got the ratings\n",
        "predicted_ratings_simple = [pred.est for pred in predicted_ratings_simple]\n",
        "\n",
        "# Get RMSE\n",
        "rmse_score_simple = np.sqrt(mean_squared_error(test_ratings, predicted_ratings_simple))\n",
        "print(\"Simple Model (SVD) RMSE:\", rmse_score_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XMG0QNeOjjp",
        "outputId": "c230d32a-1bc4-4fbd-8b1d-c19a372289b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple Model (SVD) RMSE: 0.9595426452167031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hybrid"
      ],
      "metadata": {
        "id": "FtHhC24QXR9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will process the test data to make available for prediction"
      ],
      "metadata": {
        "id": "s_3sUO9LXTTq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the SVD embeddings for the test, and concatante with the Genre embedding"
      ],
      "metadata": {
        "id": "sF44-3R0YzXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(df_test_data[['userId', 'movieId', 'rating']], reader)\n",
        "svd_model = SVD()\n",
        "svd_model.fit(data.build_full_trainset())\n",
        "svd_embeddings = svd_model.qi"
      ],
      "metadata": {
        "id": "Ei_Uto27Y1rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add in the genre to one vector"
      ],
      "metadata": {
        "id": "BSx_awdRbIv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genre_embeddings_truncated = genre_embeddings[:svd_embeddings.shape[0]]\n",
        "combined_embeddings = np.concatenate((genre_embeddings_truncated, svd_embeddings), axis=1)"
      ],
      "metadata": {
        "id": "aNVblxJYbRQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pull the predictions"
      ],
      "metadata": {
        "id": "2SSBhwHbbWoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_ratings = model_two.predict(combined_embeddings)\n",
        "rmse_score = np.sqrt(mean_squared_error(test_ratings[:combined_embeddings.shape[0]], predicted_ratings))\n",
        "print(\"RMSE:\", rmse_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QI6kTPexbPAc",
        "outputId": "eede2f50-c56d-487d-a2a8-edacfc081e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45/45 [==============================] - 0s 2ms/step\n",
            "RMSE: 1.3130233614865616\n"
          ]
        }
      ]
    }
  ]
}